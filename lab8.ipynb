{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:31:37.165430400Z",
     "start_time": "2023-11-06T17:31:37.053191200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    def __init__(self, initial_value=None):\n",
    "        self.value = initial_value\n",
    "        self.consumers = []\n",
    "\n",
    "        Graph.get_default().variables.append(self)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:31:37.170137600Z",
     "start_time": "2023-11-06T17:31:37.165430400Z"
    }
   },
   "id": "b41effebaddafd2e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Placeholder:\n",
    "    def __init__(self):\n",
    "        self.consumers = []\n",
    "\n",
    "        Graph.get_default().placeholders.append(self)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:31:38.750868400Z",
     "start_time": "2023-11-06T17:31:38.722345700Z"
    }
   },
   "id": "96ff744d85cb9982"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class Operation:\n",
    "    def __init__(self, input_nodes=None):\n",
    "        self.input_nodes = input_nodes if input_nodes is not None else []\n",
    "        self.consumers = []\n",
    "        self.inputs = None\n",
    "        self.output = None\n",
    "\n",
    "        for input_node in self.input_nodes:\n",
    "            input_node.consumers.append(self)\n",
    "\n",
    "        Graph.get_default().operations.append(self)\n",
    "\n",
    "    def compute(self, *args):\n",
    "        pass\n",
    "    \n",
    "    def gradient(self, gradient):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T18:33:22.805846Z",
     "start_time": "2023-11-06T18:33:22.777005400Z"
    }
   },
   "id": "a8d629714a0f6b3"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class Add(Operation):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__([x, y])\n",
    "\n",
    "    def compute(self, x: float, y: float) -> float:\n",
    "        return x + y\n",
    "    \n",
    "    def gradient(self, gradient):\n",
    "        x, y = self.inputs\n",
    "        \n",
    "        gradient_x, gradient_y = gradient, gradient\n",
    "        \n",
    "        while np.ndim(gradient_x) > len(x.shape):\n",
    "            gradient_x = np.sum(gradient_x, axis=0)\n",
    "        for axis, size in enumerate(x.shape):\n",
    "            if size == 1:\n",
    "                gradient_x = np.sum(gradient_x, axis=axis, keepdims=True)\n",
    "\n",
    "        while np.ndim(gradient_y) > len(y.shape):\n",
    "            gradient_y = np.sum(gradient_y, axis=0)\n",
    "        for axis, size in enumerate(y.shape):\n",
    "            if size == 1:\n",
    "                gradient_y = np.sum(gradient_y, axis=axis, keepdims=True)\n",
    "\n",
    "        return [gradient_x, gradient_y]\n",
    "\n",
    "\n",
    "class MatrixMultiplication(Operation):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__([x, y])\n",
    "\n",
    "    def compute(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        return x.dot(y)\n",
    "    \n",
    "    def gradient(self, gradient):\n",
    "        x, y = self.inputs\n",
    "        \n",
    "        return [gradient.dot(y.T), x.T.dot(gradient)]\n",
    "\n",
    "\n",
    "class Softmax(Operation):\n",
    "    def __init__(self, logits):\n",
    "        super().__init__([logits])\n",
    "\n",
    "    def compute(self, logits: np.ndarray):\n",
    "        return np.exp(logits) / np.sum(np.exp(logits), axis=1)[:, None]\n",
    "    \n",
    "    def gradient(self, gradient):\n",
    "        softmax = self.output\n",
    "        return (gradient - np.reshape(\n",
    "            np.sum(gradient * softmax, 1),\n",
    "            [-1, 1]\n",
    "        )) * softmax\n",
    "\n",
    "\n",
    "class Log(Operation):\n",
    "    def __init__(self, x):\n",
    "        super().__init__([x])\n",
    "\n",
    "    def compute(self, x: np.ndarray):\n",
    "        return np.log(x)\n",
    "    \n",
    "    def gradient(self, gradient):\n",
    "        x, = self.inputs\n",
    "        return gradient / x\n",
    "\n",
    "\n",
    "class HadamardProduct(Operation):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__([x, y])\n",
    "\n",
    "    def compute(self, x: np.ndarray, y: np.ndarray):\n",
    "        return x * y\n",
    "    \n",
    "    def gradient(self, gradient):\n",
    "        x, y = self.inputs\n",
    "        \n",
    "        return [gradient * y, gradient * x]\n",
    "\n",
    "\n",
    "class MatrixSum(Operation):\n",
    "    def __init__(self, x, axis: int = None):\n",
    "        super().__init__([x])\n",
    "        self.axis = axis\n",
    "\n",
    "    def compute(self, x: np.ndarray):\n",
    "        return np.sum(x, axis=self.axis)\n",
    "    \n",
    "    def gradient(self, gradient):\n",
    "        x, = self.inputs\n",
    "\n",
    "        output_shape = np.array(x.shape)\n",
    "        output_shape[self.axis] = 1\n",
    "        tile_scaling = x.shape // output_shape\n",
    "        gradient = np.reshape(gradient, output_shape)\n",
    "        return np.tile(gradient, tile_scaling)\n",
    "\n",
    "\n",
    "class Negative(Operation):\n",
    "    def __init__(self, x):\n",
    "        super().__init__([x])\n",
    "\n",
    "    def compute(self, x: float | np.ndarray):\n",
    "        return -x\n",
    "    \n",
    "    def gradient(self, gradient):\n",
    "        return -gradient\n",
    "\n",
    "\n",
    "class Convolution(Operation):\n",
    "    def __init__(self, x, _filter):\n",
    "        super().__init__([x, _filter])\n",
    "    \n",
    "    def compute(self, x: np.ndarray, _filter: np.ndarray):\n",
    "        x_height, x_width, *_ = x.shape\n",
    "        filter_height, filter_width, *_ = _filter.shape\n",
    "        result = np.zeros((x_height - filter_height + 1, x_width - filter_width + 1))\n",
    "        \n",
    "        for i in range(result.shape[0]):\n",
    "            for j in range(result.shape[1]):\n",
    "                result[i, j] = np.sum(x[i: i + filter_height, j: j + filter_width] * _filter)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def gradient(self, gradient):\n",
    "        input_x, input_filter = self.inputs\n",
    "        input_height, input_width, *_ = input_x.shape\n",
    "        input_filter_height, input_filter_width, input_filter_channels, *_ = input_filter.shape\n",
    "        \n",
    "        filter_gradient = np.zeros_like(input_filter)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T18:33:23.723936500Z",
     "start_time": "2023-11-06T18:33:23.691517900Z"
    }
   },
   "id": "57d3313f97e53e8"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    default = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.operations: list[Operation] = []\n",
    "        self.placeholders: list[Placeholder] = []\n",
    "        self.variables: list[Variable] = []\n",
    "\n",
    "    @classmethod\n",
    "    def get_default(cls):\n",
    "        if cls.default is None:\n",
    "            cls.default = cls()\n",
    "        return cls.default"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T18:33:25.667639700Z",
     "start_time": "2023-11-06T18:33:25.659617500Z"
    }
   },
   "id": "1a549ac9b4b7cf87"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class Session:\n",
    "    def run(self, operation, feed_dict=None):\n",
    "        if feed_dict is None:\n",
    "            feed_dict = {}\n",
    "\n",
    "        for node in traverse_postorder(operation):\n",
    "            if isinstance(node, Placeholder):\n",
    "                node.output = feed_dict[node]\n",
    "            elif isinstance(node, Variable):\n",
    "                node.output = node.value\n",
    "            elif isinstance(node, Operation):\n",
    "                node.inputs = [input_node.output for input_node in node.input_nodes]\n",
    "\n",
    "                node.output = node.compute(*node.inputs)\n",
    "\n",
    "            if isinstance(node.output, list):\n",
    "                node.output = np.array(node.output)\n",
    "\n",
    "        return operation.output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T18:33:27.608451500Z",
     "start_time": "2023-11-06T18:33:27.592355Z"
    }
   },
   "id": "e1584fafd2a8db48"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def traverse_postorder(node):\n",
    "    if isinstance(node, Operation):\n",
    "        for input_node in node.input_nodes:\n",
    "            yield from traverse_postorder(input_node)\n",
    "    yield node"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T18:33:28.506802300Z",
     "start_time": "2023-11-06T18:33:28.474425300Z"
    }
   },
   "id": "73e65f5397042f5"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def compute_gradients(loss):\n",
    "    gradient_table = {loss: 1}\n",
    "\n",
    "    visited = set()\n",
    "    queue = []\n",
    "    visited.add(loss)\n",
    "    queue.append(loss)\n",
    "\n",
    "    while queue:\n",
    "        node = queue.pop(0)\n",
    "\n",
    "        if node != loss:\n",
    "            gradient_table[node] = 0\n",
    "\n",
    "            for consumer in node.consumers:\n",
    "                upstream_gradient = gradient_table[consumer]\n",
    "                local_gradient = consumer.gradient(upstream_gradient)\n",
    "\n",
    "                if len(consumer.input_nodes) == 1:\n",
    "                    gradient_table[node] += local_gradient\n",
    "\n",
    "                else:\n",
    "                    node_index_in_consumer_inputs = consumer.input_nodes.index(node)\n",
    "                    downstream_gradient = local_gradient[node_index_in_consumer_inputs]\n",
    "                    gradient_table[node] += downstream_gradient\n",
    "\n",
    "        if hasattr(node, 'input_nodes'):\n",
    "            for input_node in node.input_nodes:\n",
    "                if not input_node in visited:\n",
    "                    visited.add(input_node)\n",
    "                    queue.append(input_node)\n",
    "\n",
    "    return gradient_table"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T18:38:54.479187900Z",
     "start_time": "2023-11-06T18:38:54.439536400Z"
    }
   },
   "id": "ad654d782e9d6c2c"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class GradientDescentOptimizer:\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def minimize(self, loss):\n",
    "        learning_rate = self.learning_rate\n",
    "\n",
    "        class MinimizationOperation(Operation):\n",
    "            def compute(self):\n",
    "                grad_table = compute_gradients(loss)\n",
    "\n",
    "                for node in grad_table:\n",
    "                    if isinstance(node, Variable):\n",
    "                        grad = grad_table[node]\n",
    "                        node.value -= learning_rate * grad\n",
    "\n",
    "        return MinimizationOperation()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T18:39:53.612084900Z",
     "start_time": "2023-11-06T18:39:53.556441600Z"
    }
   },
   "id": "a4fd72d8cef384d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    pass\n",
    "\n",
    "\n",
    "class Linear(Layer):\n",
    "    def __init__(self, input_size: int, output_size: int):\n",
    "        self.weights = Variable(np.random.randn(output_size, input_size))\n",
    "        self.bias = Variable(np.random.randn(output_size))\n",
    "        self.expression = None\n",
    "    \n",
    "    def build_expression(self, input_variable: Variable | Operation | Placeholder):\n",
    "        self.expression = Add(MatrixMultiplication(self.weights, input_variable), self.bias)    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8580ff156c88b189"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0  Loss: 105.45552948357856\n",
      "Step: 10  Loss: 1.6071027418326638\n",
      "Step: 20  Loss: 1.149579394968531\n",
      "Step: 30  Loss: 0.9443880885592876\n",
      "Step: 40  Loss: 0.8254483742083262\n",
      "Step: 50  Loss: 0.746690417168796\n",
      "Step: 60  Loss: 0.6900418734881323\n",
      "Step: 70  Loss: 0.6469102020357418\n",
      "Step: 80  Loss: 0.6126702690067443\n",
      "Step: 90  Loss: 0.5846056511080009\n",
      "Weight matrix:\n",
      " [[ 0.87893925 -1.23097457]\n",
      " [ 0.71675747 -2.62101925]]\n",
      "Bias:\n",
      " [0.53091638 0.25638074]\n"
     ]
    }
   ],
   "source": [
    "X = Placeholder()\n",
    "c = Placeholder()\n",
    "\n",
    "# Initialize weights randomly\n",
    "W = Variable(np.random.randn(2, 2))\n",
    "b = Variable(np.random.randn(2))\n",
    "\n",
    "red_points = np.random.randn(50, 2) - 2*np.ones((50, 2))\n",
    "blue_points = np.random.randn(50, 2) + 2*np.ones((50, 2))\n",
    "\n",
    "# Build perceptron\n",
    "p = Softmax(Add(MatrixMultiplication(X, W), b))\n",
    "\n",
    "# Build cross-entropy loss\n",
    "J = Negative(MatrixSum(MatrixSum(HadamardProduct(c, Log(p)), axis=1)))\n",
    "\n",
    "# Build minimization op\n",
    "minimization_op = GradientDescentOptimizer(learning_rate=0.01).minimize(J)\n",
    "\n",
    "# Build placeholder inputs\n",
    "feed_dict = {\n",
    "    X: np.concatenate((blue_points, red_points)),\n",
    "    c:\n",
    "        [[1, 0]] * len(blue_points)\n",
    "        + [[0, 1]] * len(red_points)\n",
    "\n",
    "}\n",
    "\n",
    "# Create session\n",
    "session = Session()\n",
    "\n",
    "# Perform 100 gradient descent steps\n",
    "for step in range(100):\n",
    "    J_value = session.run(J, feed_dict)\n",
    "    if step % 10 == 0:\n",
    "        print(\"Step:\", step, \" Loss:\", J_value)\n",
    "    session.run(minimization_op, feed_dict)\n",
    "\n",
    "# Print final result\n",
    "W_value = session.run(W)\n",
    "print(\"Weight matrix:\\n\", W_value)\n",
    "b_value = session.run(b)\n",
    "print(\"Bias:\\n\", b_value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T18:43:14.035084300Z",
     "start_time": "2023-11-06T18:43:13.978971100Z"
    }
   },
   "id": "d08215a3321a99c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c01d604ce0f4e333"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
