{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tarfile\n",
    "from random import choices, choice\n",
    "from math import inf\n",
    "from itertools import product, cycle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T05:28:21.797614500Z",
     "start_time": "2023-09-24T05:28:21.757248500Z"
    }
   },
   "id": "edfca75c095cca0e"
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "np.random.seed(321)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T05:28:21.845854Z",
     "start_time": "2023-09-24T05:28:21.767374Z"
    }
   },
   "id": "d1f67d60ea47d09e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Downloading the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f53ac36543d54f27"
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    \"\"\"\n",
    "    source: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "    \"\"\"\n",
    "    with open(file, 'rb') as fo:\n",
    "        data = pickle.load(fo, encoding='bytes')\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T05:28:22.001349300Z",
     "start_time": "2023-09-24T05:28:21.788372300Z"
    }
   },
   "id": "28640659e8c8ef92"
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "dataset = requests.get('https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz')\n",
    "\n",
    "with open('cifar-10-python.tar.gz', 'wb') as dataset_file:\n",
    "    dataset_file.write(dataset.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T05:30:35.629225Z",
     "start_time": "2023-09-24T05:28:21.791374800Z"
    }
   },
   "id": "7592bcaf31a3066a"
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [],
   "source": [
    "with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "    tar.extractall()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T05:30:37.019082200Z",
     "start_time": "2023-09-24T05:30:35.631228500Z"
    }
   },
   "id": "6ea3f446bd3ab31"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# \"Training\" the model or preprocessing the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e501809a6da7acc4"
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "def process_image(data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    \n",
    "    takes image as a row of 3072 elements, \n",
    "    where the first 1024 entries contain the red channel values,\n",
    "    the next 1024 the green, and the final 1024 the blue.\n",
    "    \n",
    "    returns image as an array of shape (32, 32, 3)\n",
    "    \n",
    "    \"\"\"\n",
    "    red_channel, green_channel, blue_channel = np.split(data, 3)\n",
    "    pixels = np.stack((red_channel, green_channel, blue_channel), axis=-1)\n",
    "    return np.reshape(pixels, (32, 32, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T05:30:37.029844200Z",
     "start_time": "2023-09-24T05:30:37.023600300Z"
    }
   },
   "id": "83a9094b9387fc80"
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "def process_batch(batch: np.ndarray) -> tuple[list[np.ndarray], list[int]]:\n",
    "    \"\"\"\n",
    "    \n",
    "    processes a batch and returns a tuple of a list of processed images with shape (32, 32, 3) and list of labels\n",
    "    \n",
    "    \"\"\"\n",
    "    batch_images = list(map(process_image, batch[b'data']))\n",
    "    batch_labels = batch[b'labels']\n",
    "    \n",
    "    return batch_images, batch_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T05:30:37.045599400Z",
     "start_time": "2023-09-24T05:30:37.033056300Z"
    }
   },
   "id": "7b3c3a7c5db600d9"
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [],
   "source": [
    "batch_filenames = ['cifar-10-batches-py/data_batch_1',\n",
    "                   'cifar-10-batches-py/data_batch_2',\n",
    "                   'cifar-10-batches-py/data_batch_3', \n",
    "                   'cifar-10-batches-py/data_batch_4',\n",
    "                   'cifar-10-batches-py/data_batch_5']\n",
    "\n",
    "train_images, raw_train_labels = [], []\n",
    "for filename in batch_filenames:\n",
    "    current_batch = unpickle(filename)\n",
    "    images, labels = process_batch(current_batch)\n",
    "    train_images.extend(images)\n",
    "    raw_train_labels.extend(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:25:43.197269400Z",
     "start_time": "2023-09-24T06:25:41.164799800Z"
    }
   },
   "id": "856a4c0c25b639b2"
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [],
   "source": [
    "def one_hot_encoder(labels: list[int]) -> list[np.ndarray]:\n",
    "    encoded: list[np.ndarray] = []\n",
    "    for label in labels:\n",
    "        encoded.append(np.zeros(10))\n",
    "        encoded[-1][label] = 1.0\n",
    "    return encoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:25:43.212764900Z",
     "start_time": "2023-09-24T06:25:43.201802400Z"
    }
   },
   "id": "aeebd99fa8734001"
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [],
   "source": [
    "train_labels = one_hot_encoder(raw_train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:25:43.290424400Z",
     "start_time": "2023-09-24T06:25:43.208629700Z"
    }
   },
   "id": "de1da2c5486e1555"
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [],
   "source": [
    "test_batch = unpickle('cifar-10-batches-py/test_batch')\n",
    "test_images, raw_test_labels = process_batch(test_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:25:43.678737800Z",
     "start_time": "2023-09-24T06:25:43.273900Z"
    }
   },
   "id": "9afcfa2b5f700bdf"
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [],
   "source": [
    "test_labels = one_hot_encoder(raw_test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:25:43.695147600Z",
     "start_time": "2023-09-24T06:25:43.680755Z"
    }
   },
   "id": "6b476693751f3d70"
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [],
   "source": [
    "meta_data = unpickle('cifar-10-batches-py/batches.meta')\n",
    "label_names = list(map(bytes.decode, meta_data[b'label_names']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:25:43.707748900Z",
     "start_time": "2023-09-24T06:25:43.696137300Z"
    }
   },
   "id": "5f7783ff6c5b2809"
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class Layer(ABC):\n",
    "    @abstractmethod\n",
    "    def __call__(self, x: np.ndarray, train=False) -> np.ndarray:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def backward(self, error: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "\n",
    "class Linear(Layer):\n",
    "    def __init__(self, input_size: int, output_size: int):\n",
    "        self.weights = np.random.randn(input_size, output_size)\n",
    "        self.bias = np.random.randn(1, output_size)\n",
    "        \n",
    "        self.input: np.ndarray = np.array([])\n",
    "        self.output: np.ndarray = np.array([])\n",
    "    \n",
    "    def __call__(self, x: np.ndarray, train=False) -> np.ndarray:\n",
    "        if train:\n",
    "            self.input = x\n",
    "            self.output = x @ self.weights + self.bias\n",
    "            return self.output\n",
    "        else:\n",
    "            return x @ self.weights + self.bias\n",
    "    \n",
    "    def backward(self, error: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        input_error = error @ self.weights.T\n",
    "        weights_error = self.input.T @ error\n",
    "        \n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * np.sum(error, axis=0)\n",
    "        return input_error"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:25:43.735912800Z",
     "start_time": "2023-09-24T06:25:43.705738800Z"
    }
   },
   "id": "8d16c0af52d6fa05"
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [],
   "source": [
    "class Activation(ABC):\n",
    "    @abstractmethod\n",
    "    def __call__(self, x: np.ndarray, train=False) -> np.ndarray:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def backward(self, error: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "\n",
    "class Sigmoid(Activation):\n",
    "    def __call__(self, x: np.ndarray, train=False) -> np.ndarray:\n",
    "        if train:\n",
    "            self.output = np.piecewise(\n",
    "                x, \n",
    "                [x < 0, x >= 0], \n",
    "                [lambda a: np.exp(a) / (1 + np.exp(a)), lambda a: 1 / (1 + np.exp(-a))]\n",
    "            )\n",
    "            return self.output\n",
    "        else:\n",
    "            return np.piecewise(\n",
    "                x, \n",
    "                [x < 0, x >= 0], \n",
    "                [lambda a: np.exp(a) / (1 + np.exp(a)), lambda a: 1 / (1 + np.exp(-a))]\n",
    "            )\n",
    "    \n",
    "    def backward(self, error: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        return error * self.output * (1 - self.output)\n",
    "\n",
    "\n",
    "class Softmax(Activation):\n",
    "    def __call__(self, x: np.ndarray, train=False, normalized=True) -> np.ndarray:\n",
    "        # print(f'{x=}')\n",
    "        if normalized:\n",
    "            exponents = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        else:\n",
    "            exponents = np.exp(x)\n",
    "        \n",
    "        probabilities = exponents / np.sum(exponents, axis=1, keepdims=True)\n",
    "        # print(f'{probabilities=}')\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def backward(self, error: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        return error  # only if it comes before cross entropy\n",
    "\n",
    "\n",
    "class ReLU(Activation):\n",
    "    def __call__(self, x: np.ndarray, train=False):\n",
    "        self.output = np.maximum(0, x)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, error: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        return error * (self.output > 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:25:43.752029300Z",
     "start_time": "2023-09-24T06:25:43.734907600Z"
    }
   },
   "id": "4a8363467f30ef8b"
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [],
   "source": [
    "class Loss(ABC):\n",
    "    @abstractmethod\n",
    "    def __call__(self, predicted: np.ndarray, actual: np.ndarray):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_gradient(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class CrossEntropyLoss(Loss):\n",
    "    def __init__(self):\n",
    "        self.gradient = None\n",
    "    \n",
    "    def __call__(self, predicted: np.ndarray, actual: np.ndarray):\n",
    "        log_predicted = np.log(np.clip(predicted, 1e-7, 1 - 1e-7))\n",
    "        self.gradient = (predicted - actual) / len(actual)\n",
    "        return -np.sum(actual * log_predicted, axis=1)\n",
    "    \n",
    "    def get_gradient(self):\n",
    "        return self.gradient"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:25:43.752029300Z",
     "start_time": "2023-09-24T06:25:43.745999700Z"
    }
   },
   "id": "d710bac1bd9127fc"
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, \n",
    "                 layers: list[Layer | Activation],\n",
    "                 loss: Loss):\n",
    "        self.layers = layers\n",
    "        self.loss = loss\n",
    "    \n",
    "    def __call__(self, x: np.ndarray, train=False) -> np.ndarray:\n",
    "        result = x\n",
    "        for layer in self.layers:\n",
    "            result = layer(result, train=train)\n",
    "        return result\n",
    "    \n",
    "    def backpropagation(self, learning_rate=0.001):\n",
    "        error = self.loss.get_gradient()\n",
    "        for layer in self.layers[::-1]:\n",
    "            error = layer.backward(error, learning_rate)\n",
    "    \n",
    "    def fit(self, x, y, epochs, learning_rate=0.001):\n",
    "        for i in range(epochs):\n",
    "            loss = 0\n",
    "            for batch_x, batch_y in zip(x, y):\n",
    "                output = self(batch_x, train=True)\n",
    "                loss += np.mean(self.loss(output, batch_y))\n",
    "                self.backpropagation(learning_rate)\n",
    "            print(f'epoch: {i} loss: {loss / len(x)}')\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:25:43.820849400Z",
     "start_time": "2023-09-24T06:25:43.760561200Z"
    }
   },
   "id": "3866cf097c00f2cb"
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "train_images = np.array(list(map(np.ndarray.flatten, train_images))) / 255.0\n",
    "train_labels = np.array(train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:25:44.438030800Z",
     "start_time": "2023-09-24T06:25:43.769186Z"
    }
   },
   "id": "85fa1446802376bd"
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [
    "train_images_batched = np.array_split(train_images, train_images.shape[0] // 64 + 1)\n",
    "train_labels_batched = np.array_split(train_labels, train_images.shape[0] // 64 + 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:25:44.452264500Z",
     "start_time": "2023-09-24T06:25:44.438030800Z"
    }
   },
   "id": "7e1ff5d3a7f55d3a"
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [],
   "source": [
    "model = Model([\n",
    "    Linear(3072, 128),\n",
    "    ReLU(),\n",
    "    Linear(128, 128),\n",
    "    ReLU(),\n",
    "    Linear(128, 10),\n",
    "    Softmax()],\n",
    "    loss=CrossEntropyLoss()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:30:32.368035100Z",
     "start_time": "2023-09-24T06:30:32.348998Z"
    }
   },
   "id": "d5a551ef8e13ba12"
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 2.1544491036726323\n",
      "epoch: 1 loss: 2.1510033462018185\n",
      "epoch: 2 loss: 2.147736602008187\n",
      "epoch: 3 loss: 2.144678413754983\n",
      "epoch: 4 loss: 2.1417571416277084\n",
      "epoch: 5 loss: 2.1389054254002704\n",
      "epoch: 6 loss: 2.1360601023126167\n",
      "epoch: 7 loss: 2.1334167874725827\n",
      "epoch: 8 loss: 2.1308846204156953\n",
      "epoch: 9 loss: 2.1283952281940914\n",
      "epoch: 10 loss: 2.125969176847191\n",
      "epoch: 11 loss: 2.123508346778144\n",
      "epoch: 12 loss: 2.1211029618030426\n",
      "epoch: 13 loss: 2.1187537281843336\n",
      "epoch: 14 loss: 2.1164548457271746\n",
      "epoch: 15 loss: 2.1141815139913294\n",
      "epoch: 16 loss: 2.111978672629273\n",
      "epoch: 17 loss: 2.1097852353855813\n",
      "epoch: 18 loss: 2.1077111636249977\n",
      "epoch: 19 loss: 2.1056874639701686\n",
      "epoch: 20 loss: 2.1037209749013988\n",
      "epoch: 21 loss: 2.101715520330901\n",
      "epoch: 22 loss: 2.0996572458895866\n",
      "epoch: 23 loss: 2.0976644901365966\n",
      "epoch: 24 loss: 2.0958503939032007\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_images_batched, train_labels_batched, 25, learning_rate=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:35:24.991917100Z",
     "start_time": "2023-09-24T06:33:05.204480500Z"
    }
   },
   "id": "bbc2f763ade88c3e"
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [],
   "source": [
    "test_images = list(map(np.ndarray.flatten, test_images))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:35:25.032624500Z",
     "start_time": "2023-09-24T06:35:24.983760500Z"
    }
   },
   "id": "711080ad6b94dbef"
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_predictions: 2436/10000\n",
      "accuracy: 0.2436\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for image, label in zip(test_images, test_labels):\n",
    "    prediction = model(np.array([image]) / 255.)\n",
    "    if prediction.argmax() == label.argmax():\n",
    "        correct += 1\n",
    "print(f'correct_predictions: {correct}/{len(test_images)}\\naccuracy: {correct / len(test_images)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:35:30.729250Z",
     "start_time": "2023-09-24T06:35:25.032624500Z"
    }
   },
   "id": "ab84c1140754e69a"
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for image in test_images[:10]:\n",
    "    print(model(np.array([image]) / 255.).argmax())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:24:41.460701900Z",
     "start_time": "2023-09-24T06:24:41.399959800Z"
    }
   },
   "id": "3f54fbb53f2d5920"
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "8\n",
      "8\n",
      "0\n",
      "6\n",
      "6\n",
      "1\n",
      "6\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for label in test_labels[:10]:\n",
    "    print(label.argmax())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T06:24:41.473226600Z",
     "start_time": "2023-09-24T06:24:41.433521Z"
    }
   },
   "id": "9f887c22794ec1f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c6f250ba75bfc42f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
